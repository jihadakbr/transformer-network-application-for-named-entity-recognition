
# Transformer Network Application for Named-Entity Recognition

This project was completed as a part of the Honors portion of the [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models) Course on [Coursera](https://www.coursera.org/).

Credit to DeepLearning.AI and the Coursera platform for providing the course materials and guidance.

## Objective

My objective is to utilize tokenizers and pre-trained models available in the HuggingFace Library. I aim to fine-tune a pre-trained transformer model specifically for Named-Entity Recognition (NER). By leveraging the power of pre-trained models and optimizing them for NER tasks, I aim to achieve accurate and efficient entity recognition in text data. This will enable me to enhance my skills in utilizing cutting-edge natural language processing techniques and advance my proficiency in applying transformer networks for real-world applications like Named-Entity Recognition.
## Results

![Transformer Network Application for Named-Entity Recognition](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_ca4P1negd0obO_6xc5NS3hKW9wqslreOrIqLT7Y_xouY7JGxRBWKCvzH5FXuscupY1YUZ_m4NVXJ4Xv52CbI4NrzEnQtS_RElFZI6Gg13-qed8H8l_MWjNtLxee9bUaCWat-BHpRT15MlxQpb42rN-kwNWe6Yg8-Fx_DfC8FXCrUUAn3kt5E3zb0Tfo/s1600/transformer-network-application-for-named-entity-recognition.png)